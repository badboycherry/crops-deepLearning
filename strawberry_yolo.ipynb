{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/badboycherry/crops-deepLearning/blob/main/strawberry_yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yaPW60dU8Nz",
        "outputId": "f28e8869-0372-4334-802f-a023420c9aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 셋 정리(복사)"
      ],
      "metadata": {
        "id": "wa98R9f5KlKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 원천 데이터셋이 있는 폴더\n",
        "original_dataset_dir = '/content/drive/MyDrive/1조 공유/strawberry_data/strawberry_train'\n",
        "classes_list = os.listdir(original_dataset_dir)\n",
        "\n",
        "# train, test, val 데이터를 분리시킬 폴더\n",
        "base_dir = '/content/drive/MyDrive/PROJECT/strawberry_data'\n",
        "os.mkdir(base_dir)"
      ],
      "metadata": {
        "id": "FAJKumjJKzHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 정리를 위한 목록 및 폴더 생성\n",
        "import shutil\n",
        "\n",
        "# base_dir 하위에 각각의 폴더 생성\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "os.mkdir(validation_dir)\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "# 생성된 폴더에도 기존 데이터에 있던 하위 폴더들 생성\n",
        "for cls in classes_list:\n",
        "  os.mkdir(os.path.join(train_dir, cls))\n",
        "  os.mkdir(os.path.join(validation_dir, cls))\n",
        "  os.mkdir(os.path.join(test_dir, cls))"
      ],
      "metadata": {
        "id": "EdoH9Rm-Kmyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 확인\n",
        "import math\n",
        "\n",
        "for cls in classes_list:\n",
        "  path = os.path.join(original_dataset_dir, cls) # 기존 데이터의 폴더\n",
        "  fnames = os.listdir(path) # path 폴더에 있는 파일명 저장\n",
        "\n",
        "  # 불러온 파일들을 6:2:2로 train/ val/ test로 분리\n",
        "  train_size = math.floor(len(fnames)* 0.6)\n",
        "  validation_size = math.floor(len(fnames)*0.2)\n",
        "  test_size = math.floor(len(fnames)*0.2)\n",
        "\n",
        "  # 각 인덱스에 해당하는 파일들을 각 폴더에 저장\n",
        "  train_fnames = fnames[:train_size]\n",
        "  print(f\"Train size({cls}): {len(train_fnames)}\")\n",
        "  for fname in train_fnames:\n",
        "    src = os.path.join(path, fname) # 기존 파일 경로\n",
        "    dst = os.path.join(os.path.join(train_dir, cls), fname) # copy할 파일 경로\n",
        "    shutil.copyfile(src, dst) # 새로 생성된 train dir에 파일 저장\n",
        "\n",
        "  validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
        "  print(f\"Validation size({cls}) : {len(validation_fnames)}\")\n",
        "  for fname in validation_fnames:\n",
        "    src = os.path.join(path, fname)\n",
        "    dst = os.path.join(os.path.join(validation_dir, cls), fname)\n",
        "    shutil.copyfile(src,dst) # 새로 생성된 validation dir에 파일 저장\n",
        "\n",
        "  test_fnames = fnames[(train_size + validation_size):(validation_size + train_size + test_size)]\n",
        "  print(f\"Test size({cls}) : {len(test_fnames)}\")\n",
        "  for fname in test_fnames:\n",
        "    src = os.path.join(path, fname)\n",
        "    dst = os.path.join(os.path.join(test_dir, cls), fname)\n",
        "    shutil.copyfile(src, dst) # 새로 생성된 test dir에 파일 저장"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N83TlzROKqEn",
        "outputId": "971f4ec7-c8ed-4b07-c401-07906584cad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size(strawberry_Graymold): 158\n",
            "Validation size(strawberry_Graymold) : 52\n",
            "Test size(strawberry_Graymold) : 52\n",
            "Train size(strawberry_healthy): 193\n",
            "Validation size(strawberry_healthy) : 64\n",
            "Test size(strawberry_healthy) : 64\n",
            "Train size(strawberry_mildew): 163\n",
            "Validation size(strawberry_mildew) : 54\n",
            "Test size(strawberry_mildew) : 54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 정리(이동)"
      ],
      "metadata": {
        "id": "o5bjQpbrOQgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from shutil import move\n",
        "\n",
        "# 원천 데이터셋이 있는 폴더\n",
        "original_dataset_dir = '/content/drive/MyDrive/1조 공유/strawberry_data'\n",
        "classes_list = os.listdir(original_dataset_dir)\n",
        "\n",
        "# train, test, val 데이터를 분리시킬 폴더\n",
        "base_dir = '/content/drive/MyDrive/1조 공유/strawberry_data/Strawberry'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# 데이터 정리를 위한 목록 및 폴더 생성\n",
        "for subset in ['train', 'val', 'test']:\n",
        "    os.makedirs(os.path.join(base_dir, subset), exist_ok=True)\n",
        "    for cls in classes_list:\n",
        "        os.makedirs(os.path.join(base_dir, subset, cls), exist_ok=True)\n",
        "\n",
        "# 데이터 분리 및 이동\n",
        "for cls in classes_list:\n",
        "    path = os.path.join(original_dataset_dir, cls)\n",
        "    fnames = os.listdir(path)\n",
        "\n",
        "    # train:test:val = 6:2:2 로 분리\n",
        "    train_fnames, testval_fnames = train_test_split(fnames, test_size=0.4, random_state=42)\n",
        "    test_fnames, val_fnames = train_test_split(testval_fnames, test_size=0.5, random_state=42)\n",
        "\n",
        "    # train 데이터 이동\n",
        "    for fname in train_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(base_dir, 'train', cls, fname)\n",
        "        move(src, dst)\n",
        "\n",
        "    # val 데이터 이동\n",
        "    for fname in val_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(base_dir, 'val', cls, fname)\n",
        "        move(src, dst)\n",
        "\n",
        "    # test 데이터 이동\n",
        "    for fname in test_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(base_dir, 'test', cls, fname)\n",
        "        move(src, dst)\n",
        "\n",
        "print(\"데이터 분리 및 이동 완료\")"
      ],
      "metadata": {
        "id": "3hUa3vPrOStA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e926f5dd-b053-4d67-f180-85e31aa13595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 분리 및 이동 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLO TEST"
      ],
      "metadata": {
        "id": "ygBzQeYEJRNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ultralytics : Ultralytics는 객체 검출(Object Detection), 세그멘테이션(Segmentation), 분류(Classification) 등과 같은 작업을 수행하기 위한 코드와 도구를 제공\n",
        "- torch는 PyTorch 라이브러리로, 딥 러닝 작업을 위한 인기 있는 오픈 소스 라이브러리입니다. GPU 상에서 텐서 계산, 자동 미분, 신경망 레이어 등을 제공\n",
        "- YOLO 알고리즘을 활용해 물체 검출 작업을 수행"
      ],
      "metadata": {
        "id": "4AUF2d3ia50e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6HzimYUCXNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8997276-646e-441b-b09a-a233734637a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.229-py3-none-any.whl (663 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.2/663.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.229\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "PRrxCOT1CYGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CUDA(Compute Unified Device Architecture)가 사용 가능한지 확인하는 코드\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5YZz-A2CZ5f",
        "outputId": "787ad28a-eab8-431a-969e-2eac8dd6de69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLO (You Only Look Once) 알고리즘을 사용하는 객체 검출 모델을 초기화\n",
        "# 'yolov8n-cls.pt': 미리 학습된 가중치 파일의 경로/ cls (분류)\n",
        "model = YOLO('yolov8n-cls.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtjFHCbWCbtZ",
        "outputId": "ec9769cf-913c-4efa-c395-3d17cf2dcac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-cls.pt to 'yolov8n-cls.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.28M/5.28M [00:00<00:00, 66.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch에서 CUDA(Compute Unified Device Architecture)를 사용하여 GPU 가속을 활성화하는 부분\n",
        "if torch.cuda.is_available():\n",
        "  model.to('cuda')"
      ],
      "metadata": {
        "id": "A3pPC018CdqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 학습"
      ],
      "metadata": {
        "id": "UoZ0JenjtPj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train:모델 학습 메소드\n",
        "# project : 학습된 모델과 결과물을 저장할 프로젝트 디렉토리 경로\n",
        "# imgsz : 이미지 사이\n",
        "# 이미지 복사하거나 하면 경고 뜸\n",
        "results = model.train(data='/content/drive/MyDrive/strawberry_data/Strawberry', epochs=5, imgsz=640, project='/content/drive/MyDrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7ZOSWGvCgC_",
        "outputId": "cc3a55fe-a17e-4fd5-eda7-cb17c92ea717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/drive/MyDrive/strawberry_data/Strawberry, epochs=5, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=/content/drive/MyDrive, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/train2\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/drive/.shortcut-targets-by-id/1aI-m4PcP9UcMUHMnkioIWxZj79MqZP_G/strawberry_data/Strawberry/train... found 2098 images in 11 classes: ERROR ❌️ requires 3 classes, not 11\n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/drive/.shortcut-targets-by-id/1aI-m4PcP9UcMUHMnkioIWxZj79MqZP_G/strawberry_data/Strawberry/val... found 1010 images in 7 classes: ERROR ❌️ requires 3 classes, not 7\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/drive/.shortcut-targets-by-id/1aI-m4PcP9UcMUHMnkioIWxZj79MqZP_G/strawberry_data/Strawberry/test... found 2262 images in 7 classes: ERROR ❌️ requires 3 classes, not 7\n",
            "Overriding model.yaml nc=1000 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    334083  ultralytics.nn.modules.head.Classify         [256, 3]                      \n",
            "YOLOv8n-cls summary: 99 layers, 1442131 parameters, 1442131 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/train2', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 85.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ NMS time limit 0.550s exceeded\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1aI-m4PcP9UcMUHMnkioIWxZj79MqZP_G/strawberry_data/Strawberry/train... 2098 images, 0 corrupt: 100%|██████████| 2098/2098 [13:37<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1aI-m4PcP9UcMUHMnkioIWxZj79MqZP_G/strawberry_data/Strawberry/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=640, width=640, scale=(0.5, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.30000000000000004, 1.7], hue=[-0.015, 0.015]), Normalize(p=1.0, mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1aI-m4PcP9UcMUHMnkioIWxZj79MqZP_G/strawberry_data/Strawberry/val... 1291 images, 0 corrupt: 100%|██████████| 1291/1291 [08:43<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1aI-m4PcP9UcMUHMnkioIWxZj79MqZP_G/strawberry_data/Strawberry/val.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/5      1.58G      1.231         16        640:   3%|▎         | 4/132 [00:03<01:08,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 755k/755k [00:00<00:00, 16.2MB/s]\n",
            "        1/5      1.59G     0.8067          2        640: 100%|██████████| 132/132 [15:40<00:00,  7.12s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 41/41 [07:32<00:00, 11.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.266          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/5      1.46G     0.4524          2        640: 100%|██████████| 132/132 [24:08<00:00, 10.97s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 41/41 [07:35<00:00, 11.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.246          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/5      1.46G     0.3691          2        640: 100%|██████████| 132/132 [18:41<00:00,  8.49s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 41/41 [09:43<00:00, 14.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.226          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        4/5      1.46G     0.3273          2        640: 100%|██████████| 132/132 [17:31<00:00,  7.97s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 41/41 [07:38<00:00, 11.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       0.19          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        5/5      1.45G     0.2987          2        640: 100%|██████████| 132/132 [19:54<00:00,  9.05s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 41/41 [09:21<00:00, 13.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.178          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5 epochs completed in 2.300 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/train2/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/drive/MyDrive/train2/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/drive/MyDrive/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.229 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1438723 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/drive/.shortcut-targets-by-id/1aI-m4PcP9UcMUHMnkioIWxZj79MqZP_G/strawberry_data/Strawberry/train... found 3583 images in 11 classes: ERROR ❌️ requires 3 classes, not 11\n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/drive/.shortcut-targets-by-id/1aI-m4PcP9UcMUHMnkioIWxZj79MqZP_G/strawberry_data/Strawberry/val... found 1537 images in 7 classes: ERROR ❌️ requires 3 classes, not 7\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/drive/.shortcut-targets-by-id/1aI-m4PcP9UcMUHMnkioIWxZj79MqZP_G/strawberry_data/Strawberry/test... found 2599 images in 7 classes: ERROR ❌️ requires 3 classes, not 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 41/41 [15:58<00:00, 23.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.266          1\n",
            "Speed: 0.6ms preprocess, 1.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/train2\u001b[0m\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/train2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 예측"
      ],
      "metadata": {
        "id": "Z6G2HkajtVrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련된 YOLO 모델을 로드합니다. 'best.pt' 파일은 가장 좋은 성능을 보인 모델의 가중치를 나타냄\n",
        "trained_model = YOLO('/content/drive/MyDrive/PROJECT/train5/weights/best.pt')"
      ],
      "metadata": {
        "id": "NY5A1g3qChu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련된 모델을 사용하여 이미지에서 물체를 예측\n",
        "trained_model.predict('/content/drive/MyDrive/900868_20211110_1_0_0_1_2_13_0_201.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV6scLxTCm4H",
        "outputId": "c81ea123-15c8-4236-a52c-c40d814f9529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/900868_20211110_1_0_0_1_2_13_0_201.jpg: 640x640 strawberry_healthy 0.96, strawberry_mildew 0.04, strawberry_Graymold 0.00, 4.9ms\n",
            "Speed: 9.1ms preprocess, 4.9ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: None\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'strawberry_Graymold', 1: 'strawberry_healthy', 2: 'strawberry_mildew'}\n",
              " orig_img: array([[[230, 225, 222],\n",
              "         [230, 225, 222],\n",
              "         [232, 227, 224],\n",
              "         ...,\n",
              "         [234, 224, 207],\n",
              "         [234, 224, 207],\n",
              "         [234, 224, 207]],\n",
              " \n",
              "        [[230, 225, 222],\n",
              "         [230, 225, 222],\n",
              "         [231, 226, 223],\n",
              "         ...,\n",
              "         [233, 223, 206],\n",
              "         [233, 223, 206],\n",
              "         [233, 223, 206]],\n",
              " \n",
              "        [[230, 225, 222],\n",
              "         [230, 225, 222],\n",
              "         [231, 226, 223],\n",
              "         ...,\n",
              "         [233, 223, 206],\n",
              "         [233, 223, 206],\n",
              "         [233, 223, 206]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 86, 121,  94],\n",
              "         [ 88, 123,  96],\n",
              "         [ 88, 123,  96],\n",
              "         ...,\n",
              "         [175, 176, 174],\n",
              "         [175, 176, 174],\n",
              "         [174, 175, 173]],\n",
              " \n",
              "        [[ 85, 120,  93],\n",
              "         [ 88, 123,  96],\n",
              "         [ 89, 124,  97],\n",
              "         ...,\n",
              "         [174, 175, 173],\n",
              "         [175, 176, 174],\n",
              "         [174, 175, 173]],\n",
              " \n",
              "        [[ 83, 118,  91],\n",
              "         [ 87, 122,  95],\n",
              "         [ 89, 124,  97],\n",
              "         ...,\n",
              "         [172, 173, 171],\n",
              "         [173, 174, 172],\n",
              "         [173, 174, 172]]], dtype=uint8)\n",
              " orig_shape: (4032, 3024)\n",
              " path: '/content/drive/MyDrive/900868_20211110_1_0_0_1_2_13_0_201.jpg'\n",
              " probs: ultralytics.engine.results.Probs object\n",
              " save_dir: None\n",
              " speed: {'preprocess': 9.054183959960938, 'inference': 4.894256591796875, 'postprocess': 0.0705718994140625}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'ClassifyMetrics' 객체에서 결과 딕셔너리 가져오기\n",
        "results_dict = results.results_dict\n",
        "\n",
        "# 클래스 이름과 확률을 출력\n",
        "for key, value in results_dict.items(): # 결과 딕셔너리의 각 항목에 대해 반복\n",
        "    if 'top1' in key:  # top-1 클래스의 경우\n",
        "        top1_class = key.split('_')[-1]  # 클래스 이름 추출\n",
        "        top1_probability = value # 딕셔너리의 값은 해당 클래스의 확률\n",
        "        print(f'Top-1 Class: {top1_class}') # 추출한 Top-1 클래스 이름을 출력\n",
        "        print(f'Top-1 Probability: {top1_probability}') # 추출한 Top-1 클래스의 확률을 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "gN8EPeNSCoMf",
        "outputId": "1b3cbbe0-2435-4e5a-f5a3-bf93d089aff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-2cc369be54cb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 'ClassifyMetrics' 객체에서 결과 딕셔너리 가져오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 클래스 이름과 확률을 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 결과 딕셔너리의 각 항목에 대해 반복\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'results_dict'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 예측"
      ],
      "metadata": {
        "id": "goUZwFl3tYs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model.predict('/content/drive/MyDrive/3.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8yqTdjZCqeW",
        "outputId": "36916446-2d64-4af9-bca4-93a452f12640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/3.jpg: 640x640 strawberry_mildew 0.84, strawberry_Graymold 0.12, strawberry_healthy 0.04, 53.9ms\n",
            "Speed: 2.8ms preprocess, 53.9ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: None\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'strawberry_Graymold', 1: 'strawberry_healthy', 2: 'strawberry_mildew'}\n",
              " orig_img: array([[[ 17,  17,  17],\n",
              "         [ 24,  24,  24],\n",
              "         [ 20,  20,  20],\n",
              "         ...,\n",
              "         [ 57, 122,  60],\n",
              "         [ 56, 121,  59],\n",
              "         [ 59, 123,  63]],\n",
              " \n",
              "        [[ 21,  21,  21],\n",
              "         [ 25,  25,  25],\n",
              "         [ 20,  20,  20],\n",
              "         ...,\n",
              "         [ 54, 119,  57],\n",
              "         [ 54, 119,  57],\n",
              "         [ 58, 122,  62]],\n",
              " \n",
              "        [[ 26,  26,  26],\n",
              "         [ 26,  26,  26],\n",
              "         [ 20,  20,  20],\n",
              "         ...,\n",
              "         [ 55, 120,  58],\n",
              "         [ 56, 121,  59],\n",
              "         [ 60, 124,  64]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 69,  60, 127],\n",
              "         [ 59,  64, 125],\n",
              "         [ 78,  96, 149],\n",
              "         ...,\n",
              "         [ 14,  13,  15],\n",
              "         [ 14,  16,  17],\n",
              "         [ 52,  53,  57]],\n",
              " \n",
              "        [[ 66,  68,  98],\n",
              "         [ 66,  61, 130],\n",
              "         [ 60,  54, 136],\n",
              "         ...,\n",
              "         [ 16,  17,  15],\n",
              "         [ 17,  18,  16],\n",
              "         [ 48,  49,  47]],\n",
              " \n",
              "        [[ 54,  61,  78],\n",
              "         [ 65,  65, 119],\n",
              "         [ 61,  59, 129],\n",
              "         ...,\n",
              "         [ 20,  21,  19],\n",
              "         [ 18,  19,  17],\n",
              "         [ 42,  43,  41]]], dtype=uint8)\n",
              " orig_shape: (130, 215)\n",
              " path: '/content/drive/MyDrive/3.jpg'\n",
              " probs: ultralytics.engine.results.Probs object\n",
              " save_dir: None\n",
              " speed: {'preprocess': 2.8133392333984375, 'inference': 53.86662483215332, 'postprocess': 0.05245208740234375}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'ClassifyMetrics' 객체에서 결과 딕셔너리 가져오기\n",
        "results_dict = results.results_dict\n",
        "\n",
        "# 클래스 이름과 확률을 출력\n",
        "for key, value in results_dict.items():\n",
        "    if 'top1' in key:  # top-1 클래스의 경우\n",
        "        top1_class = key.split('_')[-1]  # 클래스 이름 추출\n",
        "        top1_probability = value\n",
        "        print(f'Top-1 Class: {top1_class}')\n",
        "        print(f'Top-1 Probability: {top1_probability}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRvpbEFrCsHA",
        "outputId": "566d630e-b835-4165-931d-1833888d22ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 Class: top1\n",
            "Top-1 Probability: 0.7352941036224365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trained_model('/content/drive/MyDrive/3.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Xj8aTi7CuH3",
        "outputId": "a01a646a-1337-4fdf-ea86-0916beb1d717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/3.jpg: 640x640 strawberry_mildew 0.84, strawberry_Graymold 0.12, strawberry_healthy 0.04, 76.7ms\n",
            "Speed: 3.1ms preprocess, 76.7ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 질병 예측"
      ],
      "metadata": {
        "id": "9tsA0xe5tds8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = trained_model('/content/drive/MyDrive/1151532_20211210_1_1_a1_1_2_13_3_22.jpg') # 잿빛곰팡이병"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtiyIsQ6Cvno",
        "outputId": "48f85f2f-a72e-4e8a-cc38-2ccbd8873037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/1151532_20211210_1_1_a1_1_2_13_3_22.jpg: 640x640 strawberry_Graymold 0.78, strawberry_mildew 0.22, strawberry_healthy 0.00, 14.1ms\n",
            "Speed: 13.2ms preprocess, 14.1ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trained_model('/content/drive/MyDrive/619749_20211026_1_1_a2_3_2_12_1_76.jpg') # 흰가루병"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2iiD2PGf9pv",
        "outputId": "c2d1bec2-801d-4a96-bd13-aa8565f27111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/619749_20211026_1_1_a2_3_2_12_1_76.jpg: 640x640 strawberry_mildew 1.00, strawberry_Graymold 0.00, strawberry_healthy 0.00, 16.5ms\n",
            "Speed: 18.6ms preprocess, 16.5ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trained_model('/content/drive/MyDrive/620081_20211026_1_1_a2_3_2_12_1_116.jpg') # 흰가루병"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgId90hmgbEp",
        "outputId": "0de9a42f-3cd8-49d7-d771-6c69c6d15ab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/620081_20211026_1_1_a2_3_2_12_1_116.jpg: 640x640 strawberry_mildew 1.00, strawberry_Graymold 0.00, strawberry_healthy 0.00, 4.1ms\n",
            "Speed: 7.1ms preprocess, 4.1ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trained_model('/content/drive/MyDrive/900870_20211110_1_0_0_1_2_13_0_203.jpg') # 정상과일"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7vChS6aUnpb",
        "outputId": "2ca928ac-afa0-423e-b764-4c6fa2059e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/900870_20211110_1_0_0_1_2_13_0_203.jpg: 640x640 strawberry_healthy 1.00, strawberry_Graymold 0.00, strawberry_mildew 0.00, 4.0ms\n",
            "Speed: 12.2ms preprocess, 4.0ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trained_model('/content/drive/MyDrive/694432_20211102_1_0_0_3_2_12_0_720.jpg') # 정상 잎사귀 -> mildew로 판단함"
      ],
      "metadata": {
        "id": "S6bK5aS-giEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25d73dcc-13dd-4e49-fea0-8a69856d6eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/694432_20211102_1_0_0_3_2_12_0_720.jpg: 640x640 strawberry_mildew 1.00, strawberry_healthy 0.00, strawberry_Graymold 0.00, 3.8ms\n",
            "Speed: 7.4ms preprocess, 3.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6LpPxdnzUzq_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}